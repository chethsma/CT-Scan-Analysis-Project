{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec3ec4-b7dd-45cc-956b-b8765e6d3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from scipy import ndimage\n",
    "from IPython.display import display, HTML\n",
    "import glob\n",
    "from multiprocessing import Pool\n",
    "import concurrent.futures\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import save_model\n",
    "import glob\n",
    "from keras.preprocessing import image\n",
    "from multiprocessing import Pool\n",
    "from sklearn.cluster import KMeans\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "from collections import Counter\n",
    "import time\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3951a00-6443-43a3-baa4-c93213d61865",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dicom_img(num):\n",
    "    source_path=r\"C:\\Users\\schet\\OneDrive\\Desktop\\MSS-2\\Final_dicom_data\"\n",
    "    img_path=os.path.join(source_path,dcm_id['ID_complete'][num])\n",
    "    dicom_img=pydicom.dcmread(img_path)\n",
    "    return dicom_img\n",
    "\n",
    "def transform_HU(dicom_meta):\n",
    "    image=dicom_meta.pixel_array\n",
    "    slope=dicom_meta.RescaleSlope\n",
    "    intercept=dicom_meta.RescaleIntercept\n",
    "    hu_array=image*slope+intercept\n",
    "    \n",
    "    return hu_array\n",
    "\n",
    "def window_image(image,window_centre,window_width):\n",
    "    img_min=(window_centre-window_width)/2\n",
    "    img_max=(window_centre+window_width)/2\n",
    "    win_image=image.copy()\n",
    "    win_image[win_image<img_min]=img_min\n",
    "    win_image[win_image>img_max]=img_max\n",
    "    \n",
    "    return win_image\n",
    "\n",
    "\n",
    "def normalize(image):\n",
    "    min_=image.min()\n",
    "    max_=image.max()\n",
    "    return (image-min_)/(max_-min_)\n",
    "\n",
    "def map_ct_to_grayscale(ct_image):\n",
    "    # Normalize pixel values to the range [0, 1]\n",
    "    normalized_image = cv.normalize(ct_image, None, 0, 1, cv.NORM_MINMAX)\n",
    "    # Map the normalized values to the 8-bit range [0, 255]\n",
    "    mapped_image = (normalized_image * 255).astype(np.uint8)\n",
    "\n",
    "    return mapped_image\n",
    "\n",
    "def add_padding(image, new_height=512, new_width=512):\n",
    "    height, width = image.shape[:2]\n",
    "    final_image = np.zeros((new_height, new_width,3), dtype=np.uint8)\n",
    "\n",
    "    pad_left = int((new_width - width) // 2)\n",
    "    pad_top = int((new_height - height) // 2)\n",
    "    # Replace the pixels with the image's pixels\n",
    "    final_image[pad_top:pad_top + height, pad_left:pad_left + width] = image\n",
    "    \n",
    "    return final_image\n",
    "\n",
    "def crop(image):\n",
    "    labeled_blobs, number_of_blobs = ndimage.label(image)\n",
    "    blob_sizes = np.bincount(labeled_blobs.flatten())\n",
    "\n",
    "    blob_sizes_sorted = sorted(blob_sizes)\n",
    "    pos_2large = np.where(blob_sizes == (blob_sizes_sorted[-2]))[0][0]\n",
    "    blob_0 = labeled_blobs == pos_2large\n",
    "    blob_0 = np.max(blob_0, axis=-1)\n",
    "    \n",
    "    mask=blob_0==0\n",
    "    rows = np.flatnonzero((~mask).sum(axis=1))\n",
    "    cols = np.flatnonzero((~mask).sum(axis=0))\n",
    "    \n",
    "    # keeping offset from cropping deep\n",
    "    offset=10\n",
    "    x_min = max([rows.min() - offset, 0])\n",
    "    x_max = min([rows.max() + offset + 1, image.shape[0]])\n",
    "    y_min = max([cols.min() - offset, 0])\n",
    "    y_max = min([cols.max() + offset + 1, image.shape[1]])\n",
    "    \n",
    "    return [x_min,x_max,y_min,y_max]\n",
    "    \n",
    "\n",
    "def has_brain(r):\n",
    "\n",
    "    img = (r.pixel_array * r.RescaleSlope) + r.RescaleIntercept \n",
    "    img = img.astype(np.int16) \n",
    "  \n",
    "    brain_img = np.clip(img, 20, 45)\n",
    "    brain_img[brain_img==20] = 0\n",
    "    brain_img[brain_img==45] = 0\n",
    "    status=1 if brain_img.mean()>0.0 else 0\n",
    "\n",
    "    has_brain = np.sum(brain_only) > 0\n",
    "    return has_brain\n",
    "\n",
    "def dcm_array(path):\n",
    "    meta=pydicom.dcmread(path)\n",
    "    image=meta.pixel_array\n",
    "    slope=meta.RescaleSlope\n",
    "    intercept=meta.RescaleIntercept\n",
    "    hu_array=image*slope+intercept\n",
    "    \n",
    "    return hu_array\n",
    "# scaling images to gray scale\n",
    "def scale_dicom_pixel_values(image_hu):\n",
    "    min_val = np.min(image_hu)\n",
    "    max_val = np.max(image_hu)\n",
    "    scaled_image = ((image_hu - min_val) / (max_val - min_val) * 255).astype(np.uint8)\n",
    "    return scaled_image\n",
    "\n",
    "def severity(path):\n",
    "    original_ct=dcm_array(path)\n",
    "    win_img=window_image(original_ct,35,300)\n",
    "\n",
    "    h,w=win_img.shape\n",
    "    x, y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "\n",
    "    image_flat = win_img.flatten().reshape(-1,1)\n",
    "\n",
    "    num_clusters=7\n",
    "    kmeans = KMeans(n_clusters=num_clusters,n_init=10,random_state=42)\n",
    "    kmeans.fit(image_flat)\n",
    "\n",
    "    labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    # creating the dictonary of information about each cluster\n",
    "    cluster_info = {'cluster_num': [],'min': [], 'max': [], 'range': [], 'average': [],'pixel_count': []}\n",
    "    pixel_counts = Counter(labels)\n",
    "    for i in range(num_clusters):\n",
    "\n",
    "        cluster_pixels = image_flat[labels == i]\n",
    "\n",
    "    \n",
    "        min_val = np.min(cluster_pixels)\n",
    "        max_val = np.max(cluster_pixels)\n",
    "        range_val = max_val - min_val\n",
    "        average_val = np.mean(cluster_pixels)\n",
    "\n",
    "        # Store information in the dictionary\n",
    "        cluster_info['cluster_num'].append(i)\n",
    "        cluster_info['min'].append(min_val)\n",
    "        cluster_info['max'].append(max_val)\n",
    "        cluster_info['range'].append(range_val)\n",
    "        cluster_info['average'].append(average_val)\n",
    "        cluster_info['pixel_count'].append(pixel_counts[i])\n",
    "    # ordering the custers based on mean of pixel frequncies of each cluster\n",
    "    zipped_values = zip(cluster_info['cluster_num'], cluster_info['min'], cluster_info['max'], cluster_info['range'], cluster_info['average'],cluster_info['pixel_count'])\n",
    "    sorted_values = sorted(zipped_values, key=lambda x: x[4])\n",
    "\n",
    "    segmented_image = labels.reshape(win_img.shape)\n",
    "    colored_image = np.zeros_like(win_img)\n",
    "    for i in range(1):\n",
    "        colored_image[segmented_image == i] = np.random.randint(0, 255)\n",
    "    _, binary_mask = cv.threshold(win_img, 150, 255, cv.THRESH_BINARY)\n",
    "\n",
    "    selected_cluster=sorted_values[-2][0]\n",
    "    mask = (labels == selected_cluster).reshape(h, w)\n",
    "    clustred=image_flat[labels == 0]\n",
    "    background_color = 0\n",
    "    new_image = np.full_like(win_img, background_color)\n",
    "    new_image[mask] = win_img[mask]\n",
    "\n",
    "    # calculating the size of hemohrages relative to the size of brain and presented in percentage.\n",
    "    hem_cells_den=(sorted_values[-2][-1]/(262144-sorted_values[0][-1]))*100\n",
    "    #display image\n",
    "    orignal_scan=scale_dicom_pixel_values(original_ct)\n",
    "    result_scan=scale_dicom_pixel_values(new_image)\n",
    "    #enhancing intensity of result image by value 50\n",
    "    result_scan=cv.add(result_scan,50)\n",
    "    mask = result_scan > 50\n",
    "    result_img = np.where(mask, result_scan, orignal_scan)\n",
    "    \n",
    "#     plt.figure(figsize=(15,15))\n",
    "#     plt.subplot(131);plt.imshow(original_ct);plt.axis('off')\n",
    "#     plt.subplot(132);plt.imshow(new_image); plt.title('Brain & Skull Part');plt.axis('off')\n",
    "#     plt.subplot(133);plt.imshow(result_img); plt.title(f\"Damage Severity= {np.round(hem_cells_den,2)}%\");plt.axis('off')\n",
    "    return [result_img,hem_cells_den]\n",
    "    \n",
    "\n",
    "# prediction of models and severity of hemorrhages\n",
    "# test_path = 'takes jpg image \n",
    "def Prediction_Severity_Analysis(models,target_sizes,test_path):\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = io.StringIO()\n",
    "\n",
    "    # calculating the predictions of all models\n",
    "    predictions = []\n",
    "    for model, target_size in zip(models, target_sizes):\n",
    "        img = image.load_img(test_path, target_size=target_size)\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = img_array/ 255.0\n",
    "        model_prediction = model.predict(img_array)\n",
    "        predictions.append(model_prediction)\n",
    "        \n",
    "    sys.stdout = old_stdout\n",
    "    pred=predictions[0][0]\n",
    "    hemo_status=\"No Hemorrhages Detected\"\n",
    "    # if prediction is positve then we will peform the severity analysis\n",
    "    if predictions[0][0]>0.5:\n",
    "        hemo_status=\"Hemorrhages Detected\"\n",
    "        file_name = os.path.basename(test_path)\n",
    "        id_part = file_name.split('_')[1].split('.')[0]\n",
    "        # change path to extract image to run predictions\n",
    "        test_dicom_path = fr\"C:\\Users\\schet\\OneDrive\\Desktop\\DICOM_\\test_dicom\\ID_{id_part}.dcm\"\n",
    "        sev_pred=severity(test_dicom_path)\n",
    "        return [pred,hemo_status,sev_pred]\n",
    "    else:\n",
    "        return [pred,hemo_status]\n",
    "\n",
    "    \n",
    "#pre-processing the CT scan and saving in JPG format\n",
    "def Preprocess(path):\n",
    "    dcm_meta = pydicom.dcmread(path, force=True)\n",
    "        \n",
    "        # Extract pixel array and convert to Hounsfield Units (HU)\n",
    "    dcm_img = dcm_meta.pixel_array\n",
    "    image_hu = (dcm_meta.pixel_array * dcm_meta.RescaleSlope) + dcm_meta.RescaleIntercept\n",
    "        \n",
    "        # Apply windowing to create different views\n",
    "    brain_win = window_image(image_hu, 40, 80)         # Brain window\n",
    "    subdural_win = window_image(image_hu, 80, 200)      # Subdural window\n",
    "    bone_win = window_image(image_hu, 400, 1800)        # Bone window\n",
    "        \n",
    "        # Combine the three window scales into a three-channel image\n",
    "    image_raw = np.dstack((map_ct_to_grayscale(brain_win), map_ct_to_grayscale(subdural_win), map_ct_to_grayscale(bone_win)))\n",
    "        \n",
    "        # Crop the image\n",
    "    crop_loc = crop(image_raw)\n",
    "    image_crop = image_raw[crop_loc[0]:crop_loc[1], crop_loc[2]:crop_loc[3]]\n",
    "        \n",
    "        # Add padding to the cropped image\n",
    "    image_pad = add_padding(image_crop)\n",
    "        \n",
    "        # Denoise the colored image\n",
    "    final_image = cv.fastNlMeansDenoisingColored(image_pad, None, 1, 2, 7, 9)\n",
    "    \n",
    "    folder=r\"C:\\Users\\schet\\OneDrive\\Desktop\\DICOM_\\stored_jpg\"\n",
    "    output_path=os.path.join(folder,os.path.basename(path).replace('dcm','jpg'))\n",
    "    cv.imwrite(output_path,final_image)\n",
    "    \n",
    "    while not os.path.exists(output_path):\n",
    "        time.sleep(1)\n",
    "\n",
    "    sev_pred=Prediction_Severity_Analysis(models, target_sizes, output_path)\n",
    "    return sev_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dece81e6-da1a-49b9-adb8-d6efa3494ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths=[r\"C:\\Users\\schet\\OneDrive\\Desktop\\Model Weights\\ResNetrs100.h5\",\n",
    "            r\"C:\\Users\\schet\\OneDrive\\Desktop\\Model Weights\\resnet50_model.h5\",\n",
    "            r\"C:\\Users\\schet\\OneDrive\\Desktop\\Model Weights\\InceptionV3.h5\",\n",
    "            r\"C:\\Users\\schet\\OneDrive\\Desktop\\Model Weights\\VGG19.h5\"\n",
    "           ]\n",
    "\n",
    "models=[load_model(model_path) for model_path in model_paths]\n",
    "target_sizes=[(512, 512),(512, 512),(512, 512,3),(512, 512, 3)]\n",
    "test_path=r\"C:\\Users\\schet\\OneDrive\\Desktop\\DICOM_\\test_dicom\\ID_00b5b2ae3.dcm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d8b254-5f5c-48fa-8198-4b4c0ed672a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3236429-69d2-45b4-93f7-0591a4487fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocesss(path,out_folder):\n",
    "    dcm_meta = pydicom.dcmread(path, force=True)\n",
    "        \n",
    "        # Extract pixel array and convert to Hounsfield Units (HU)\n",
    "    dcm_img = dcm_meta.pixel_array\n",
    "    image_hu = (dcm_meta.pixel_array * dcm_meta.RescaleSlope) + dcm_meta.RescaleIntercept\n",
    "        \n",
    "        # Apply windowing to create different views\n",
    "    brain_win = window_image(image_hu, 40, 80)         # Brain window\n",
    "    subdural_win = window_image(image_hu, 80, 200)      # Subdural window\n",
    "    bone_win = window_image(image_hu, 400, 1800)        # Bone window\n",
    "        \n",
    "        # Combine the three window scales into a three-channel image\n",
    "    image_raw = np.dstack((map_ct_to_grayscale(brain_win), map_ct_to_grayscale(subdural_win), map_ct_to_grayscale(bone_win)))\n",
    "        \n",
    "        # Crop the image\n",
    "    crop_loc = crop(image_raw)\n",
    "    image_crop = image_raw[crop_loc[0]:crop_loc[1], crop_loc[2]:crop_loc[3]]\n",
    "        \n",
    "        # Add padding to the cropped image\n",
    "    image_pad = add_padding(image_crop)\n",
    "        \n",
    "        # Denoise the colored image\n",
    "    final_image = cv.fastNlMeansDenoisingColored(image_pad, None, 1, 2, 7, 9)\n",
    "    \n",
    "    \n",
    "    output_path=os.path.join(folder,os.path.basename(path).replace('dcm','jpg'))\n",
    "    cv.imwrite(output_path,final_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b808c6-2b35-4504-84b9-e11bbb610b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder=r\"C:\\Users\\schet\\OneDrive\\Desktop\\test_1\"\n",
    "test_folder=r\"C:\\Users\\schet\\OneDrive\\Desktop\\test_data_folder\"\n",
    "\n",
    "def preprocess_and_convert(test_folder, output_folder):\n",
    "\n",
    "    # Iterate through DICOM files in the test folder\n",
    "    for root, dirs, files in os.walk(test_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".dcm\"):\n",
    "                dicom_path = os.path.join(root, file)\n",
    "                Preprocesss(dicom_path, output_folder)\n",
    "preprocess_and_convert(test_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bbedd3-231c-456c-9385-62e42ace5ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def browse_files():\n",
    "    # Clear previous outputs\n",
    "    output_text.delete(1.0, tk.END)\n",
    "\n",
    "    # Check if there is an existing image label\n",
    "    if hasattr(process_file, 'img_label'):\n",
    "        process_file.img_label.destroy()\n",
    "\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"DICOM files\", \"*.dcm\")])\n",
    "    if file_path:\n",
    "        process_button.config(state=tk.NORMAL)\n",
    "        global selected_file\n",
    "        selected_file = file_path\n",
    "\n",
    "def process_file():\n",
    "    mm = Preprocess(selected_file)\n",
    "\n",
    "    # Check if there is an existing image label\n",
    "    if hasattr(process_file, 'img_label'):\n",
    "        process_file.img_label.destroy()\n",
    "\n",
    "    if len(mm) > 1:\n",
    "        output_text.insert(tk.END, f\"Status: {mm[1]}\\n\")\n",
    "        output_text.insert(tk.END, f\"Prediction Probability: {mm[0][0] * 100:.2f}%\")\n",
    "\n",
    "        img = mm[2][0]\n",
    "        img_pil = Image.fromarray(img)\n",
    "\n",
    "        # Display the original DICOM image using matplotlib\n",
    "        dicom_data = pydicom.dcmread(selected_file)\n",
    "        plt.figure()\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(dicom_data.pixel_array, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Original DICOM Image\")\n",
    "\n",
    "        # Display the processed image using matplotlib\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(img_pil)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Damage Severity: {mm[2][1]:.2f}%\")\n",
    "\n",
    "        # Embed the matplotlib plot into the Tkinter window\n",
    "        canvas = FigureCanvasTkAgg(plt.gcf(), master=output_text.master)\n",
    "        canvas.draw()\n",
    "\n",
    "        # Place the embedded plot in the Tkinter window\n",
    "        canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=1)\n",
    "\n",
    "        \n",
    "        # Save the label reference to be able to destroy it later\n",
    "        process_file.img_label = canvas.get_tk_widget()\n",
    "\n",
    "    else:\n",
    "        output_text.insert(tk.END, f\"Status: {mm[1]}\\n\")\n",
    "        output_text.insert(tk.END, f\"Prediction Probability: {mm[0][0] * 100:.2f}%\")\n",
    "\n",
    "# GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"DICOM File Processor\")\n",
    "\n",
    "# Set the window size to full-screen\n",
    "screen_width = root.winfo_screenwidth()\n",
    "screen_height = root.winfo_screenheight()\n",
    "root.geometry(f\"{screen_width}x{screen_height}\")\n",
    "\n",
    "# Configure the background color\n",
    "root.configure(bg=\"lightblue\")\n",
    "\n",
    "# Widgets\n",
    "browse_button = tk.Button(root, text=\"Browse\", command=browse_files, font=(\"Times New Roman\", 16), height=2, width=20)\n",
    "process_button = tk.Button(root, text=\"Run Diagonosis\", command=process_file, state=tk.DISABLED, font=(\"Times New Roman\", 16), height=2, width=20)\n",
    "output_text = tk.Text(root, height=5, width=40, font=(\"Times New Roman\", 14))\n",
    "\n",
    "# Layout\n",
    "browse_button.pack(side=tk.LEFT, anchor=tk.NW, padx=10, pady=10)\n",
    "process_button.pack(side=tk.LEFT, anchor=tk.NW, padx=10, pady=10)\n",
    "output_text.pack(side=tk.TOP, anchor=tk.NW, padx=10, pady=10)\n",
    "\n",
    "# Run the GUI\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
